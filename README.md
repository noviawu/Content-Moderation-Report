## Content-Moderation-Report

The **Content Moderation in Encrypted Platforms Report** is a document that aims to provide an overview of available technical infrastructures that balance **privacy** and **content moderation**. The report is intended to serve as a general guide for social platforms and encrypted services to understand the possibility of addressing this dilemma. The report calls for companies to consider implementing technical solutions to combat online misconduct through moderation.


Balancing privacy concerns and combating online crime such as sexual exploitation has been an ongoing debate. With the rise of social media and encrypted messaging services, it's harder to responsibly moderate content while preserving users' privacy. Many companies found themselves having to take sides, either guaranteeing privacy with little to no moderation or centralizing moderation with a strict takedown and banning rule. Because of the encrypted nature of some messaging apps and the promise to keep users' data private, companies struggle to find technical solutions that support effective content moderation.


To address this question, this report focuses on synthesizing and analyzing the current landscape of technical solutions that deal with this dilemma. The report can serve as a guide for companies and platforms to stay updated with new technologies.


We will first explain the concept of E2EE and the difficulty of content moderation on such a platform. Then we will explore the possible technical solutions, tackling the problem from prevention and reporting. Prevention techniques mainly involve detection of harmful content and analysis of behaviors to stop potential malicious users from posting. Report techniques mainly involve attribution of malicious content.


We found that the most effective prevention technique should focus on providing transparency and ensuring accountability through publicly verifiable hashing, and the most effective report mechanism should focus on holding malicious users accountable. Through the report, we hope to provide concrete guidelines for companies and platforms to take action and actively research and implement technical infrastructures to moderate content ethically.
